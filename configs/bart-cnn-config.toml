[dataset]
train_path = "reddit-syac/train.csv"
val_path = "reddit-syac/dev.csv"
test_path = "reddit-syac/test.csv"

[model]
# Model name determines checkpoint and directory and 
name = "bart-large-cnn"
tokenizer_path = "facebook/bart-large-cnn"
model_path = "facebook/bart-large-cnn"
train_max_input_length = 1024

[preprocessor]
sep_token = '|'
cased = true

[train]

[train.training_args]
num_train_epochs = 20
per_device_eval_batch_size = 8
per_device_train_batch_size = 8
warmup_steps = 500
learning_rate = 1e-5
logging_steps = 50
save_strategy = "steps"
evaluation_strategy = "steps"
save_steps = 256
eval_steps = 256
weight_decay = 0.01
save_total_limit = 3

[train.early_stopping]
early_stopping_patience = 8
# early_stopping_threshold = 0.001
